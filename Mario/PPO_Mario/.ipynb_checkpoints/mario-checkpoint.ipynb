{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9857a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda\\envs\\cudapy7\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 无法在设置线程模式后对其加以更改。\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\temp\\ipykernel_24700\\2517231923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "#env = gym_super_mario_bros.make('SuperMarioBros-v0',apply_api_compatibility=True,render_mode=\"human\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "done = True\n",
    "for step in range(5000):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    time.sleep(0.01)\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f671f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0',apply_api_compatibility=True,render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb3401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849e1f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./tensorboard_log/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda\\envs\\cudapy7\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 60   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 34   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041102834 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.000646    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.438       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.0252      |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011172474 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0675      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378408 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014827537 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.0165      |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 41         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02120911 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.0236     |\n",
      "|    value_loss           | 1.89       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009877676 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.391       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 2.99e-06    |\n",
      "|    value_loss           | 4.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011589801 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017295916 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.74        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00842     |\n",
      "|    value_loss           | 6.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015879808 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.311       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00587     |\n",
      "|    value_loss           | 5.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010949511 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+04    |\n",
      "|    ep_rew_mean          | 658         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010136104 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 0.636       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+04    |\n",
      "|    ep_rew_mean          | 658         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024931084 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.00207     |\n",
      "|    value_loss           | 8.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+04    |\n",
      "|    ep_rew_mean          | 658         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019264493 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+04    |\n",
      "|    ep_rew_mean          | 658         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008965788 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "#from gym wrappers import GrayScaleObservation\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "#env = GrayScaleObservation(env)\n",
    "\n",
    "tensorboard_log=r'./tensorboard_log/'\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=tensorboard_log)\n",
    "model.learn(total_timesteps=30000)\n",
    "model.save(\"ppo_cartpole\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51fc3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9057c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.3\n"
     ]
    }
   ],
   "source": [
    "import tensorboard\n",
    "print(tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7cf6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = 'True'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73207019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: False\n",
      "CUDA version: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4adf579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available: \", cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "from gym.wrappers import Gray\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "tensorboard_log=r'./tensorboard_log/'\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=tensorboard_log)\n",
    "model.learn(total_timesteps=1000000)\n",
    "model.save(\"ppo_cartpole\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007120fe",
   "metadata": {},
   "source": [
    "The reward function assumes the objective of the game is to move as far right as possible (increase the agent's x value), as fast as possible, without dying. To model this game, three separate variables compose the reward:\n",
    "\n",
    "v: the difference in agent x values between states\n",
    "in this case this is instantaneous velocity for the given step\n",
    "v = x1 - x0\n",
    "x0 is the x position before the step\n",
    "x1 is the x position after the step\n",
    "moving right ⇔ v > 0\n",
    "moving left ⇔ v < 0\n",
    "not moving ⇔ v = 0\n",
    "\n",
    "c: the difference in the game clock between frames\n",
    "the penalty prevents the agent from standing still\n",
    "c = c0 - c1\n",
    "c0 is the clock reading before the step\n",
    "c1 is the clock reading after the step\n",
    "no clock tick ⇔ c = 0\n",
    "clock tick ⇔ c < 0\n",
    "\n",
    "d: a death penalty that penalizes the agent for dying in a state\n",
    "this penalty encourages the agent to avoid death\n",
    "alive ⇔ d = 0\n",
    "dead ⇔ d = -15\n",
    "\n",
    "r = v + c + d\n",
    "\n",
    "The reward is clipped into the range (-15, 15)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
